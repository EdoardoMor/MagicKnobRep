{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2834,"status":"ok","timestamp":1692190982506,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"AUk8TQCYzAAe","outputId":"49f998ea-84df-4ad3-c365-0f4907881333"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Othercomputers/Il mio computer/MagicKnob\n","/content/drive/Othercomputers/Il mio computer/MagicKnob/python\n"]}],"source":["import os\n","from datetime import datetime\n","\n","working_path = os.getcwd()\n","print(working_path)\n","\n","if working_path == '/content':\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    %cd /content/drive/Othercomputers/Il mio computer/MagicKnob\n","\n","    path = \"/content/drive/Othercomputers/Il mio computer/MagicKnob/\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}tensorflow\"\n","    %cd ./python\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\"\n","else:\n","    path = \"../\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6987,"status":"ok","timestamp":1692190989487,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"Wgz6WkLZzHDM"},"outputs":[],"source":["import myk_data_par\n","import myk_models\n","import myk_loss\n","import myk_train\n","import myk_evaluate_par\n","\n","import torch\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5219,"status":"ok","timestamp":1692190994702,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"mX_cQAvgzMLR"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1692190994704,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"FXrHBuv6zQPg"},"outputs":[],"source":["# used for the writing of example outputs\n","run_name=\"audio_lstm_lpf2_par\"\n","# dataset : need an input and output folder in this folder\n","audio_folder = f\"../data/{run_name}\"\n","#audio_folder = \"../../data/audio_ht1\"\n","assert os.path.exists(audio_folder), f\"Audio folder  not found. Looked for {audio_folder}\"\n","# used to render example output during training\n","test_file = \"../data/guitar.wav\"\n","assert os.path.exists(test_file), \"Test file not found. Looked for \" + test_file"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1692190994705,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"wJPGiuLV0ylP"},"outputs":[],"source":["# initialize net specs\n","lstm_hidden_size = 16\n","learning_rate = 5e-3\n","last_learning_rate = learning_rate\n","batch_size = 50\n","max_epochs = 10000\n","\n","# create the logger for tensorboard\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14542,"status":"ok","timestamp":1692191009228,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"izzFWaHj0zej","outputId":"0972f7e9-22da-4428-8d38-d24cf48a1281"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading dataset from folder  ../data/audio_lstm_lpf2_par\n","loading input and output of filter\n","    loading output of filter with parameter 0\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (120, 22050, 2)\n","    total output shape: (120, 22050, 1)\n","\n","    loading output of filter with parameter 0.25\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (240, 22050, 2)\n","    total output shape: (240, 22050, 1)\n","\n","    loading output of filter with parameter 0.5\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (360, 22050, 2)\n","    total output shape: (360, 22050, 1)\n","\n","    loading output of filter with parameter 0.75\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (480, 22050, 2)\n","    total output shape: (480, 22050, 1)\n","\n","    loading output of filter with parameter 1\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (600, 22050, 2)\n","    total output shape: (600, 22050, 1)\n","\n","total input tensor shape torch.Size([600, 22050, 2])\n","total output tensor shape torch.Size([600, 22050, 1])\n","Splitting dataset\n"]}],"source":["print(\"Loading dataset from folder \", audio_folder)\n","dataset = myk_data_par.generate_dataset(audio_folder + \"/input/\", audio_folder + \"/output/\", frag_len_seconds=0.5)\n","\n","print(\"Splitting dataset\")\n","train_ds, val_ds, test_ds = myk_data_par.get_train_valid_test_datasets(dataset)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1692191009229,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"p5wnmGGzU1KX","outputId":"ac6d6c5c-a659-4322-c729-e08b57250892"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-3.0518e-05,  0.0000e+00],\n","         [-3.0518e-05,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00]]),\n"," tensor([[ 0.0000e+00],\n","         [ 0.0000e+00],\n","         [ 0.0000e+00],\n","         ...,\n","         [-2.0146e-05],\n","         [-2.0146e-05],\n","         [-2.0146e-05]]))"]},"metadata":{},"execution_count":7}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNbGbujobejD","executionInfo":{"status":"ok","timestamp":1692191009229,"user_tz":-120,"elapsed":19,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}},"outputId":"f9ea7402-9231-4798-9db9-fc99e91547c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda device available\n"]}],"source":["\n","# test GPU, must be done after splitting\n","device = myk_train.get_device()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1692191009230,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"D3WztACX2UOd"},"outputs":[],"source":["# create data loaders\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14236,"status":"ok","timestamp":1692191023449,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"8JZL-Qqa2ORT","outputId":"0b42772e-5f83-43f8-adf4-491ef6b61731"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleLSTM(\n","  (lstm): LSTM(2, 16, batch_first=True)\n","  (dense): Linear(in_features=16, out_features=1, bias=True)\n",")\n"]},{"output_type":"execute_result","data":{"text/plain":["(None, 1297)"]},"metadata":{},"execution_count":10}],"source":["model = myk_models.SimpleLSTM(hidden_size=lstm_hidden_size, param=True).to(device)\n","total_params = sum(p.numel() for p in model.parameters())\n","print(model), total_params"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1692191023450,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"4CuDKuR92cxv"},"outputs":[],"source":["# crate optimizer and loss function\n","optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', factor=0.5, patience=5, verbose=True)\n","\n","loss_functions = myk_loss.LossWrapper()\n","\n","# https://github.com/Alec-Wright/Automated-GuitarAmpModelling/blob/main/dist_model_recnet.py\n","# https://github.com/Alec-Wright/CoreAudioML/blob/bad9469f94a2fa63a50d70ff75f5eff2208ba03f/training.py"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1692191023450,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"-6cmEvsqHwL7"},"outputs":[],"source":["#%load_ext tensorboard\n","#%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":676861,"status":"ok","timestamp":1692191700292,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"L2_vgpXU2tvW","outputId":"44a65113-8409-44a9-dff2-c9737be1a4eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0, train_loss 0.6598613858222961, val_loss 0.37372493743896484 \n","    Record loss - saving at epoch 1\n","    epoch 1, train_loss 0.3120269477367401, val_loss 0.3421986401081085 \n","    Record loss - saving at epoch 2\n","    epoch 2, train_loss 0.27395808696746826, val_loss 0.30640238523483276 \n","    Record loss - saving at epoch 3\n","    epoch 3, train_loss 0.23291225731372833, val_loss 0.19740939140319824 \n","    Record loss - saving at epoch 4\n","    epoch 4, train_loss 0.1566520482301712, val_loss 0.1522417664527893 \n","    Record loss - saving at epoch 8\n","    epoch 8, train_loss 0.09092861413955688, val_loss 0.10962925851345062 \n","    Record loss - saving at epoch 9\n","    epoch 9, train_loss 0.08143144845962524, val_loss 0.10064828395843506 \n","    Record loss - saving at epoch 12\n","    epoch 12, train_loss 0.06584140658378601, val_loss 0.06474564969539642 \n","    Record loss - saving at epoch 15\n","    epoch 15, train_loss 0.05745453014969826, val_loss 0.05455046147108078 \n","    Record loss - saving at epoch 16\n","    epoch 16, train_loss 0.05709867179393768, val_loss 0.054017238318920135 \n","Epoch 00023: reducing learning rate of group 0 to 2.5000e-03.\n","    Record loss - saving at epoch 23\n","    epoch 23, train_loss 0.04784310236573219, val_loss 0.04582221060991287 \n","    Record loss - saving at epoch 24\n","    epoch 24, train_loss 0.046940211206674576, val_loss 0.042263127863407135 \n","Epoch 00031: reducing learning rate of group 0 to 1.2500e-03.\n","    Record loss - saving at epoch 32\n","    epoch 32, train_loss 0.044128481298685074, val_loss 0.03712039068341255 \n","Epoch 00039: reducing learning rate of group 0 to 6.2500e-04.\n","    Record loss - saving at epoch 43\n","    epoch 43, train_loss 0.04182501137256622, val_loss 0.035357337445020676 \n","Epoch 00050: reducing learning rate of group 0 to 3.1250e-04.\n","epoch 50, train_loss 0.041544221341609955, val_loss 0.03887035325169563 \n","Epoch 00056: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00062: reducing learning rate of group 0 to 7.8125e-05.\n","    Record loss - saving at epoch 66\n","    epoch 66, train_loss 0.040302861481904984, val_loss 0.03304465115070343 \n","Epoch 00073: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00079: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00085: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00091: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00097: reducing learning rate of group 0 to 2.4414e-06.\n","epoch 100, train_loss 0.03994721174240112, val_loss 0.03589735925197601 \n","Epoch 00103: reducing learning rate of group 0 to 1.2207e-06.\n","    Record loss - saving at epoch 103\n","    epoch 103, train_loss 0.03954118490219116, val_loss 0.031597036868333817 \n","Epoch 00110: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00116: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00122: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00128: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00134: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00140: reducing learning rate of group 0 to 1.9073e-08.\n","epoch 150, train_loss 0.03917057067155838, val_loss 0.036196526139974594 \n","    Record loss - saving at epoch 166\n","    epoch 166, train_loss 0.0397806353867054, val_loss 0.029007336124777794 \n","epoch 200, train_loss 0.039881300181150436, val_loss 0.03462991863489151 \n","epoch 250, train_loss 0.03956408426165581, val_loss 0.038257427513599396 \n","epoch 300, train_loss 0.0399818979203701, val_loss 0.03254898637533188 \n","epoch 350, train_loss 0.03961137309670448, val_loss 0.037437647581100464 \n","epoch 400, train_loss 0.039316002279520035, val_loss 0.03842318430542946 \n","epoch 450, train_loss 0.03968536853790283, val_loss 0.03821501135826111 \n","epoch 500, train_loss 0.03986300155520439, val_loss 0.03935415297746658 \n","epoch 550, train_loss 0.03963668644428253, val_loss 0.036245688796043396 \n","epoch 600, train_loss 0.03977494314312935, val_loss 0.033623211085796356 \n","epoch 650, train_loss 0.03959987312555313, val_loss 0.03955351933836937 \n","max patience reached, stopping training\n"]}],"source":["# training loop\n","lowest_val_loss = 0\n","best_loss = False\n","\n","max_patience = 500\n","curr_patience = max_patience\n","\n","# datetime object containing current date and time\n","best_epoch = 0\n","now = datetime.now()\n","dt_string = now.strftime(f\"models/{model.model_type}_%d-%m-%Y_%H-%M-%S\")\n","\n","os.mkdir(os.path.join(\".\", dt_string))\n","\n","with open(f'{dt_string}/model_structure.txt', \"w\") as model_structure:\n","    model_structure.write(str(model))\n","    model_structure.write(f\"total params: {total_params}\")\n","\n","for epoch in range(max_epochs):\n","    #ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\n","    ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\n","\n","    #ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimiser, device=device)\n","    val_loss = myk_train.compute_batch_loss(model, val_dl, loss_functions, device=device)\n","    scheduler.step(val_loss);\n","\n","    if learning_rate != last_learning_rate:\n","      print(f\"LR step {learning_rate}\")\n","\n","    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n","    writer.add_scalar(\"Loss/train\", ep_loss, epoch)\n","\n","    # check if we have beaten our best loss to date\n","    if lowest_val_loss == 0:# first run\n","        lowest_val_loss = val_loss\n","    elif val_loss < lowest_val_loss:# new record\n","        lowest_val_loss = val_loss\n","        best_loss = True\n","    else: # no improvement\n","        best_loss = False\n","        curr_patience -= 1\n","\n","    if best_loss: # save best model so far\n","        best_epoch = epoch\n","        print(f\"    Record loss - saving at epoch {epoch}\")\n","        # save for RTNeural\n","        model.save_for_rtneural(f\"{dt_string}/model.json\")\n","        # save for pythorch\n","        torch.save(model.state_dict(), f\"{dt_string}/model.ph\")\n","        print(f\"    epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","        curr_patience = max_patience\n","    if epoch % 50 == 0: # save an example processed audio file\n","        myk_evaluate_par.run_file_through_model(model, test_file, audio_folder + \"/\" + run_name + str(epoch)+\".wav\")\n","        print(f\"epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","    if curr_patience == 0:\n","        print(\"max patience reached, stopping training\")\n","        # load best parameters in the model\n","        model.load_state_dict(torch.load(f\"{dt_string}/model.ph\"))\n","        model.eval() # set inference state in the possible layers that need it\n","        myk_evaluate_par.run_file_through_model(model, test_file, audio_folder + \"/\" + run_name + str(best_epoch)+\"_BEST.wav\", final_eval=True)\n","        break"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1165,"status":"ok","timestamp":1692191701441,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"edQeVKnKqIlY"},"outputs":[],"source":["to_append = [f'\\n{run_name}/*.wav', f'\\n!{run_name}/*_BEST*.wav']\n","\n","with open(f'{audio_folder}/../.gitignore', \"r+\") as gitignore:\n","    read = gitignore.read()\n","    if to_append[0][2:len(to_append[0])] not in read:\n","        gitignore.writelines(to_append)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1R90W11c0RiDl3RfZT-sX8pRNVVVbmSYh","timestamp":1685016693193}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}