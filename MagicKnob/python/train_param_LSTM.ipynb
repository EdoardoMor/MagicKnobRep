{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44945,"status":"ok","timestamp":1692796539489,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"AUk8TQCYzAAe","outputId":"31e9e8e1-2ce3-4d7e-a0e4-8b8be77a2373"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Mounted at /content/drive\n","/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob\n","/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/python\n"]}],"source":["import os\n","from datetime import datetime\n","\n","working_path = os.getcwd()\n","print(working_path)\n","\n","if working_path == '/content':\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    %cd /content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob\n","\n","    path = \"/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","    %cd ./python\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\"\n","else:\n","    path = \"../\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8736,"status":"ok","timestamp":1692796548223,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"Wgz6WkLZzHDM"},"outputs":[],"source":["import myk_data_par\n","import myk_models\n","import myk_loss\n","import myk_train\n","import myk_evaluate_par\n","\n","import torch\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3929,"status":"ok","timestamp":1692796552150,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"mX_cQAvgzMLR"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1692796552596,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"FXrHBuv6zQPg"},"outputs":[],"source":["# used for the writing of example outputs\n","run_name=\"audio_logic_dist_par\"\n","# dataset : need an input and output folder in this folder\n","audio_folder = f\"../data/{run_name}\"\n","#audio_folder = \"../../data/audio_ht1\"\n","assert os.path.exists(audio_folder), f\"Audio folder  not found. Looked for {audio_folder}\"\n","# used to render example output during training\n","test_file = \"../data/guitar.wav\"\n","assert os.path.exists(test_file), \"Test file not found. Looked for \" + test_file"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692796552597,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"wJPGiuLV0ylP"},"outputs":[],"source":["# initialize net specs\n","lstm_hidden_size = 16\n","learning_rate = 5e-3\n","last_learning_rate = learning_rate\n","batch_size = 50\n","max_epochs = 10000\n","\n","# create the logger for tensorboard\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":56165,"status":"ok","timestamp":1692796608759,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"izzFWaHj0zej","colab":{"base_uri":"https://localhost:8080/"},"outputId":"33ffabc6-8631-43ff-d458-02663edac1a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading dataset from folder  ../data/audio_logic_dist_par\n","loading input and output of logicdist\n","    loading output of logicdist with parameter 0.02\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (120, 22050, 2)\n","    total output shape: (120, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.04\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (240, 22050, 2)\n","    total output shape: (240, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.06\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (360, 22050, 2)\n","    total output shape: (360, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.08\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (480, 22050, 2)\n","    total output shape: (480, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.1\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (600, 22050, 2)\n","    total output shape: (600, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.12\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (720, 22050, 2)\n","    total output shape: (720, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.14\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (840, 22050, 2)\n","    total output shape: (840, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.16\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (960, 22050, 2)\n","    total output shape: (960, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.18\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1080, 22050, 2)\n","    total output shape: (1080, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.2\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1200, 22050, 2)\n","    total output shape: (1200, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.22\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1320, 22050, 2)\n","    total output shape: (1320, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.24\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1440, 22050, 2)\n","    total output shape: (1440, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.26\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1560, 22050, 2)\n","    total output shape: (1560, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.28\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1680, 22050, 2)\n","    total output shape: (1680, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.3\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1800, 22050, 2)\n","    total output shape: (1800, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.32\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1920, 22050, 2)\n","    total output shape: (1920, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.34\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2040, 22050, 2)\n","    total output shape: (2040, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.36\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2160, 22050, 2)\n","    total output shape: (2160, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.38\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2280, 22050, 2)\n","    total output shape: (2280, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.4\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2400, 22050, 2)\n","    total output shape: (2400, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.42\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2520, 22050, 2)\n","    total output shape: (2520, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.44\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2640, 22050, 2)\n","    total output shape: (2640, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.46\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2760, 22050, 2)\n","    total output shape: (2760, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.48\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2880, 22050, 2)\n","    total output shape: (2880, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.5\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3000, 22050, 2)\n","    total output shape: (3000, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.52\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3120, 22050, 2)\n","    total output shape: (3120, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.54\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3240, 22050, 2)\n","    total output shape: (3240, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.56\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3360, 22050, 2)\n","    total output shape: (3360, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.58\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3480, 22050, 2)\n","    total output shape: (3480, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.6\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3600, 22050, 2)\n","    total output shape: (3600, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.62\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3720, 22050, 2)\n","    total output shape: (3720, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.64\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3840, 22050, 2)\n","    total output shape: (3840, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.68\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3960, 22050, 2)\n","    total output shape: (3960, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.7\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4080, 22050, 2)\n","    total output shape: (4080, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.72\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4200, 22050, 2)\n","    total output shape: (4200, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.74\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4320, 22050, 2)\n","    total output shape: (4320, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.76\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4440, 22050, 2)\n","    total output shape: (4440, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.78\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4560, 22050, 2)\n","    total output shape: (4560, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.8\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4680, 22050, 2)\n","    total output shape: (4680, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.82\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4800, 22050, 2)\n","    total output shape: (4800, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.84\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4920, 22050, 2)\n","    total output shape: (4920, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.86\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5040, 22050, 2)\n","    total output shape: (5040, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.88\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5160, 22050, 2)\n","    total output shape: (5160, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.9\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5280, 22050, 2)\n","    total output shape: (5280, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.92\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5400, 22050, 2)\n","    total output shape: (5400, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.94\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5520, 22050, 2)\n","    total output shape: (5520, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.96\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5640, 22050, 2)\n","    total output shape: (5640, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.98\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5760, 22050, 2)\n","    total output shape: (5760, 22050, 1)\n","\n","    loading output of logicdist with parameter 1\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5880, 22050, 2)\n","    total output shape: (5880, 22050, 1)\n","\n","total input tensor shape torch.Size([5880, 22050, 2])\n","total output tensor shape torch.Size([5880, 22050, 1])\n","Splitting dataset\n"]}],"source":["print(\"Loading dataset from folder \", audio_folder)\n","\n","input_folder = \"/input/\"\n","output_folder = \"/output_randomMany/\"\n","\n","dataset = myk_data_par.generate_dataset(audio_folder + input_folder, audio_folder + output_folder, frag_len_seconds=0.5)\n","\n","print(\"Splitting dataset\")\n","train_ds, val_ds, test_ds = myk_data_par.get_train_valid_test_datasets(dataset)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692796608760,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"p5wnmGGzU1KX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb4c6a59-d2d2-4161-d8e1-c44c7e7f6f6b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-6.1035e-05,  2.0000e-02],\n","         [-1.8311e-04,  2.0000e-02],\n","         [-1.8311e-04,  2.0000e-02],\n","         ...,\n","         [ 0.0000e+00,  2.0000e-02],\n","         [ 0.0000e+00,  2.0000e-02],\n","         [ 0.0000e+00,  2.0000e-02]]),\n"," tensor([[-6.1035e-05],\n","         [-1.5259e-04],\n","         [-1.8311e-04],\n","         ...,\n","         [-9.1553e-05],\n","         [-9.1553e-05],\n","         [-6.1035e-05]]))"]},"metadata":{},"execution_count":7}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692796608760,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"FNbGbujobejD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fced9e6d-e505-45cd-cc9a-fecd305ea989"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda device available\n"]}],"source":["# test GPU, must be done after splitting\n","device = myk_train.get_device()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692796608760,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"D3WztACX2UOd"},"outputs":[],"source":["# create data loaders\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":11535,"status":"ok","timestamp":1692796620293,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"8JZL-Qqa2ORT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d3302988-3813-4a2c-add0-2457da07b791"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleLSTM(\n","  (lstm): LSTM(2, 16, batch_first=True)\n","  (dense): Linear(in_features=16, out_features=1, bias=True)\n",")\n"]},{"output_type":"execute_result","data":{"text/plain":["(None, 1297)"]},"metadata":{},"execution_count":10}],"source":["model = myk_models.SimpleLSTM(hidden_size=lstm_hidden_size, param=True).to(device)\n","total_params = sum(p.numel() for p in model.parameters())\n","print(model), total_params"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692796620293,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"4CuDKuR92cxv"},"outputs":[],"source":["# crate optimizer and loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n","\n","loss_functions = myk_loss.LossWrapper()\n","\n","# https://github.com/Alec-Wright/Automated-GuitarAmpModelling/blob/main/dist_model_recnet.py\n","# https://github.com/Alec-Wright/CoreAudioML/blob/bad9469f94a2fa63a50d70ff75f5eff2208ba03f/training.py"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692796620294,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"-6cmEvsqHwL7"},"outputs":[],"source":["# %load_ext tensorboard\n","# %tensorboard --logdir runs"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9225025,"status":"ok","timestamp":1692805845316,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"L2_vgpXU2tvW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dae6a215-5c71-4b0f-8ddc-994393d294c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0, train_loss 0.18877896666526794, val_loss 0.18649597465991974 \n","    Record loss - saving at epoch 1\n","    epoch 1, train_loss 0.16599775850772858, val_loss 0.16013415157794952 \n","    Record loss - saving at epoch 7\n","    epoch 7, train_loss 0.1624847799539566, val_loss 0.15866796672344208 \n","    Record loss - saving at epoch 12\n","    epoch 12, train_loss 0.1629391610622406, val_loss 0.1553790420293808 \n","    Record loss - saving at epoch 14\n","    epoch 14, train_loss 0.16197621822357178, val_loss 0.15458525717258453 \n","Epoch 00021: reducing learning rate of group 0 to 2.5000e-03.\n","    Record loss - saving at epoch 25\n","    epoch 25, train_loss 0.15977855026721954, val_loss 0.15359361469745636 \n","Epoch 00032: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00038: reducing learning rate of group 0 to 6.2500e-04.\n","    Record loss - saving at epoch 39\n","    epoch 39, train_loss 0.1602579802274704, val_loss 0.15323595702648163 \n","Epoch 00046: reducing learning rate of group 0 to 3.1250e-04.\n","epoch 50, train_loss 0.16047577559947968, val_loss 0.15522149205207825 \n","Epoch 00052: reducing learning rate of group 0 to 1.5625e-04.\n","    Record loss - saving at epoch 54\n","    epoch 54, train_loss 0.15804985165596008, val_loss 0.15298740565776825 \n","Epoch 00061: reducing learning rate of group 0 to 7.8125e-05.\n","    Record loss - saving at epoch 61\n","    epoch 61, train_loss 0.158107727766037, val_loss 0.15188068151474 \n","    Record loss - saving at epoch 62\n","    epoch 62, train_loss 0.15883104503154755, val_loss 0.15175248682498932 \n","Epoch 00069: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00075: reducing learning rate of group 0 to 1.9531e-05.\n","    Record loss - saving at epoch 80\n","    epoch 80, train_loss 0.1561402827501297, val_loss 0.15127576887607574 \n","Epoch 00087: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00093: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00099: reducing learning rate of group 0 to 2.4414e-06.\n","    Record loss - saving at epoch 99\n","    epoch 99, train_loss 0.15792419016361237, val_loss 0.15091830492019653 \n","epoch 100, train_loss 0.1582903414964676, val_loss 0.15419621765613556 \n","Epoch 00106: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00112: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00118: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00124: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00130: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00136: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00142: reducing learning rate of group 0 to 1.9073e-08.\n","epoch 150, train_loss 0.15807418525218964, val_loss 0.15206828713417053 \n","epoch 200, train_loss 0.1747482717037201, val_loss 0.15281528234481812 \n","    Record loss - saving at epoch 237\n","    epoch 237, train_loss 0.15676994621753693, val_loss 0.1509099304676056 \n","epoch 250, train_loss 0.15702402591705322, val_loss 0.15305660665035248 \n","    Record loss - saving at epoch 294\n","    epoch 294, train_loss 0.16072823107242584, val_loss 0.15062573552131653 \n","epoch 300, train_loss 0.1587309092283249, val_loss 0.1533384919166565 \n","epoch 350, train_loss 0.1592937856912613, val_loss 0.15098585188388824 \n","epoch 400, train_loss 0.1572771966457367, val_loss 0.153005912899971 \n","    Record loss - saving at epoch 422\n","    epoch 422, train_loss 0.1601688265800476, val_loss 0.15042518079280853 \n","epoch 450, train_loss 0.18125088512897491, val_loss 0.1538463681936264 \n","epoch 500, train_loss 0.1596539467573166, val_loss 0.1524076908826828 \n","epoch 550, train_loss 0.15795396268367767, val_loss 0.15276171267032623 \n","epoch 600, train_loss 0.15809397399425507, val_loss 0.15308235585689545 \n","epoch 650, train_loss 0.16581271588802338, val_loss 0.15259866416454315 \n","epoch 700, train_loss 0.15974590182304382, val_loss 0.15195144712924957 \n","epoch 750, train_loss 0.15952152013778687, val_loss 0.15296603739261627 \n","epoch 800, train_loss 0.1573238968849182, val_loss 0.15157698094844818 \n","epoch 850, train_loss 0.15868006646633148, val_loss 0.1540174037218094 \n","epoch 900, train_loss 0.15675652027130127, val_loss 0.15208637714385986 \n","max patience reached, stopping training\n"]}],"source":["# training loop\n","lowest_val_loss = 0\n","best_loss = False\n","\n","max_patience = 500\n","curr_patience = max_patience\n","\n","# datetime object containing current date and time\n","best_epoch = 0\n","now = datetime.now()\n","dt_string = now.strftime(f\"models/{model.model_type}_%d-%m-%Y_%H-%M-%S\")\n","\n","os.mkdir(os.path.join(\".\", dt_string))\n","\n","with open(f'{dt_string}/model_structure.txt', \"w\") as model_structure:\n","    model_structure.write(str(model))\n","    model_structure.write(f\"total params: {total_params}\")\n","\n","results_folder = audio_folder + \"/results\"\n","if not os.path.exists(results_folder):\n","    os.mkdir(results_folder)\n","results_folder += output_folder\n","if not os.path.exists(results_folder):\n","    os.mkdir(results_folder)\n","\n","for epoch in range(max_epochs):\n","    #ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimizer, device=device)\n","    ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimizer, device=device)\n","\n","    #ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimizer, device=device)\n","    val_loss = myk_train.compute_batch_loss(model, val_dl, loss_functions, device=device)\n","    scheduler.step(val_loss);\n","\n","    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n","    writer.add_scalar(\"Loss/train\", ep_loss, epoch)\n","    writer.add_scalar(\"LR\", optimizer.param_groups[0]['lr'], epoch)\n","\n","    # check if we have beaten our best loss to date\n","    if lowest_val_loss == 0:# first run\n","        lowest_val_loss = val_loss\n","    elif val_loss < lowest_val_loss:# new record\n","        lowest_val_loss = val_loss\n","        best_loss = True\n","    else: # no improvement\n","        best_loss = False\n","        curr_patience -= 1\n","\n","    if best_loss: # save best model so far\n","        best_epoch = epoch\n","        print(f\"    Record loss - saving at epoch {epoch}\")\n","        # save for RTNeural\n","        model.save_for_rtneural(f\"{dt_string}/model.json\")\n","        # save for pythorch\n","        torch.save(model.state_dict(), f\"{dt_string}/model.ph\")\n","        print(f\"    epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","        curr_patience = max_patience\n","    if epoch % 50 == 0: # save an example processed audio file\n","        myk_evaluate_par.run_file_through_model(model, test_file, results_folder + run_name + str(epoch)+\".wav\")\n","        print(f\"epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","    if curr_patience == 0:\n","        print(\"max patience reached, stopping training\")\n","        # load best parameters in the model\n","        model.load_state_dict(torch.load(f\"{dt_string}/model.ph\"))\n","        model.eval() # set inference state in the possible layers that need it\n","        myk_evaluate_par.run_file_through_model(model, test_file, results_folder + run_name + str(best_epoch)+\"_BEST.wav\", final_eval=True)\n","        break"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":1150,"status":"ok","timestamp":1692807367054,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"edQeVKnKqIlY"},"outputs":[],"source":["to_append = [f'\\n{run_name}/**/*.wav', f'\\n!{run_name}/**/*_BEST*.wav', f'\\n!{run_name}/output*/*.wav']\n","\n","with open(f'{audio_folder}/../.gitignore', \"r+\") as gitignore:\n","    read = gitignore.read()\n","    if to_append[0][2:len(to_append[0])] not in read:\n","        gitignore.writelines(to_append)\n","    if to_append_output[2:len(to_append_output)] not in read:\n","        gitignore.writelines(to_append_output)"]},{"cell_type":"code","source":[],"metadata":{"id":"bgINnmoeLAfU"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1R90W11c0RiDl3RfZT-sX8pRNVVVbmSYh","timestamp":1685016693193}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}