{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47015,"status":"ok","timestamp":1692890084307,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"AUk8TQCYzAAe","outputId":"94c7ab44-1be0-4fab-fe69-f81d715ea587"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Mounted at /content/drive\n","/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob\n","/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/python\n"]}],"source":["import os\n","from datetime import datetime\n","\n","working_path = os.getcwd()\n","print(working_path)\n","\n","if working_path == '/content':\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    %cd /content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob\n","\n","    path = \"/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","    %cd ./python\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\"\n","else:\n","    path = \"../\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8431,"status":"ok","timestamp":1692890092735,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"Wgz6WkLZzHDM"},"outputs":[],"source":["import myk_data_par\n","import myk_models\n","import myk_loss\n","import myk_train\n","import myk_evaluate_par\n","\n","import torch\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2852,"status":"ok","timestamp":1692890095585,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"mX_cQAvgzMLR"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1197,"status":"ok","timestamp":1692890096780,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"FXrHBuv6zQPg"},"outputs":[],"source":["# used for the writing of example outputs\n","run_name=\"audio_logic_dist_par\"\n","# dataset : need an input and output folder in this folder\n","audio_folder = f\"../data/{run_name}\"\n","#audio_folder = \"../../data/audio_ht1\"\n","assert os.path.exists(audio_folder), f\"Audio folder  not found. Looked for {audio_folder}\"\n","# used to render example output during training\n","test_file = \"../data/guitar.wav\"\n","assert os.path.exists(test_file), \"Test file not found. Looked for \" + test_file"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1692890096780,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"wJPGiuLV0ylP"},"outputs":[],"source":["# initialize net specs\n","lstm_hidden_size = 32\n","learning_rate = 5e-3\n","last_learning_rate = learning_rate\n","batch_size = 50\n","max_epochs = 10000\n","\n","# create the logger for tensorboard\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":51569,"status":"ok","timestamp":1692890148346,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"izzFWaHj0zej","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51077d19-a7c7-4d7f-f5e6-0c9618093523"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading dataset from folder  ../data/audio_logic_dist_par\n","loading input and output of logicdist\n","    loading output of logicdist with parameter 0.02\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (120, 22050, 2)\n","    total output shape: (120, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.04\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (240, 22050, 2)\n","    total output shape: (240, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.06\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (360, 22050, 2)\n","    total output shape: (360, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.08\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (480, 22050, 2)\n","    total output shape: (480, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.1\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (600, 22050, 2)\n","    total output shape: (600, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.12\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (720, 22050, 2)\n","    total output shape: (720, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.14\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (840, 22050, 2)\n","    total output shape: (840, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.16\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (960, 22050, 2)\n","    total output shape: (960, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.18\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1080, 22050, 2)\n","    total output shape: (1080, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.2\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1200, 22050, 2)\n","    total output shape: (1200, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.22\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1320, 22050, 2)\n","    total output shape: (1320, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.24\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1440, 22050, 2)\n","    total output shape: (1440, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.26\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1560, 22050, 2)\n","    total output shape: (1560, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.28\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1680, 22050, 2)\n","    total output shape: (1680, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.3\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1800, 22050, 2)\n","    total output shape: (1800, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.32\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (1920, 22050, 2)\n","    total output shape: (1920, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.34\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2040, 22050, 2)\n","    total output shape: (2040, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.36\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2160, 22050, 2)\n","    total output shape: (2160, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.38\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2280, 22050, 2)\n","    total output shape: (2280, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.4\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2400, 22050, 2)\n","    total output shape: (2400, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.42\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2520, 22050, 2)\n","    total output shape: (2520, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.44\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2640, 22050, 2)\n","    total output shape: (2640, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.46\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2760, 22050, 2)\n","    total output shape: (2760, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.48\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (2880, 22050, 2)\n","    total output shape: (2880, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.5\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3000, 22050, 2)\n","    total output shape: (3000, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.52\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3120, 22050, 2)\n","    total output shape: (3120, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.54\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3240, 22050, 2)\n","    total output shape: (3240, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.56\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3360, 22050, 2)\n","    total output shape: (3360, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.58\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3480, 22050, 2)\n","    total output shape: (3480, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.6\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3600, 22050, 2)\n","    total output shape: (3600, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.62\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3720, 22050, 2)\n","    total output shape: (3720, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.64\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3840, 22050, 2)\n","    total output shape: (3840, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.68\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (3960, 22050, 2)\n","    total output shape: (3960, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.7\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4080, 22050, 2)\n","    total output shape: (4080, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.72\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4200, 22050, 2)\n","    total output shape: (4200, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.74\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4320, 22050, 2)\n","    total output shape: (4320, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.76\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4440, 22050, 2)\n","    total output shape: (4440, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.78\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4560, 22050, 2)\n","    total output shape: (4560, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.8\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4680, 22050, 2)\n","    total output shape: (4680, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.82\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4800, 22050, 2)\n","    total output shape: (4800, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.84\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (4920, 22050, 2)\n","    total output shape: (4920, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.86\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5040, 22050, 2)\n","    total output shape: (5040, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.88\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5160, 22050, 2)\n","    total output shape: (5160, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.9\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5280, 22050, 2)\n","    total output shape: (5280, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.92\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5400, 22050, 2)\n","    total output shape: (5400, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.94\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5520, 22050, 2)\n","    total output shape: (5520, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.96\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5640, 22050, 2)\n","    total output shape: (5640, 22050, 1)\n","\n","    loading output of logicdist with parameter 0.98\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5760, 22050, 2)\n","    total output shape: (5760, 22050, 1)\n","\n","    loading output of logicdist with parameter 1\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (5880, 22050, 2)\n","    total output shape: (5880, 22050, 1)\n","\n","total input tensor shape torch.Size([5880, 22050, 2])\n","total output tensor shape torch.Size([5880, 22050, 1])\n","Splitting dataset\n"]}],"source":["print(\"Loading dataset from folder \", audio_folder)\n","\n","input_folder = \"/input/\"\n","output_folder = \"/output_randomMany/\"\n","\n","dataset = myk_data_par.generate_dataset(audio_folder + input_folder, audio_folder + output_folder, frag_len_seconds=0.5)\n","\n","print(\"Splitting dataset\")\n","train_ds, val_ds, test_ds = myk_data_par.get_train_valid_test_datasets(dataset)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692890148346,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"p5wnmGGzU1KX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d6c73a92-635d-479d-e5b0-ef89fe5c73cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-6.1035e-05,  2.0000e-02],\n","         [-1.8311e-04,  2.0000e-02],\n","         [-1.8311e-04,  2.0000e-02],\n","         ...,\n","         [ 0.0000e+00,  2.0000e-02],\n","         [ 0.0000e+00,  2.0000e-02],\n","         [ 0.0000e+00,  2.0000e-02]]),\n"," tensor([[-6.1035e-05],\n","         [-1.5259e-04],\n","         [-1.8311e-04],\n","         ...,\n","         [-9.1553e-05],\n","         [-9.1553e-05],\n","         [-6.1035e-05]]))"]},"metadata":{},"execution_count":7}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692890148347,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"FNbGbujobejD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed87cc4a-7430-46df-ca02-36a24a450af5"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda device available\n"]}],"source":["# test GPU, must be done after splitting\n","device = myk_train.get_device()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1692890148347,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"D3WztACX2UOd"},"outputs":[],"source":["# create data loaders\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10485,"status":"ok","timestamp":1692890158828,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"8JZL-Qqa2ORT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3503c896-336a-4418-f3e4-b28e961521b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleLSTM(\n","  (lstm): LSTM(2, 32, batch_first=True)\n","  (dense): Linear(in_features=32, out_features=1, bias=True)\n",")\n"]},{"output_type":"execute_result","data":{"text/plain":["(None, 4641)"]},"metadata":{},"execution_count":10}],"source":["model = myk_models.SimpleLSTM(hidden_size=lstm_hidden_size, param=True).to(device)\n","total_params = sum(p.numel() for p in model.parameters())\n","print(model), total_params"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692890158828,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"4CuDKuR92cxv"},"outputs":[],"source":["# crate optimizer and loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n","\n","loss_functions = myk_loss.LossWrapper()\n","\n","# https://github.com/Alec-Wright/Automated-GuitarAmpModelling/blob/main/dist_model_recnet.py\n","# https://github.com/Alec-Wright/CoreAudioML/blob/bad9469f94a2fa63a50d70ff75f5eff2208ba03f/training.py"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692890158829,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"-6cmEvsqHwL7"},"outputs":[],"source":["# %load_ext tensorboard\n","# %tensorboard --logdir runs"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5840392,"status":"ok","timestamp":1692895999217,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"L2_vgpXU2tvW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"77107492-5463-4d2c-b670-4a7efd88b099"},"outputs":[{"output_type":"stream","name":"stdout","text":["../data/audio_logic_dist_par/results/output_randomMan32/\n","epoch 0, train_loss 0.18491320312023163, val_loss 0.1759820431470871 \n","    Record loss - saving at epoch 5\n","    epoch 5, train_loss 0.16589859127998352, val_loss 0.15493762493133545 \n","    Record loss - saving at epoch 9\n","    epoch 9, train_loss 0.16622485220432281, val_loss 0.15212075412273407 \n","Epoch 00016: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00022: reducing learning rate of group 0 to 1.2500e-03.\n","    Record loss - saving at epoch 24\n","    epoch 24, train_loss 0.16513824462890625, val_loss 0.15069617331027985 \n","    Record loss - saving at epoch 29\n","    epoch 29, train_loss 0.17037805914878845, val_loss 0.14631198346614838 \n","Epoch 00036: reducing learning rate of group 0 to 6.2500e-04.\n","    Record loss - saving at epoch 36\n","    epoch 36, train_loss 0.16338016092777252, val_loss 0.14505372941493988 \n","Epoch 00043: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00049: reducing learning rate of group 0 to 1.5625e-04.\n","epoch 50, train_loss 0.1630009114742279, val_loss 0.14887110888957977 \n","    Record loss - saving at epoch 52\n","    epoch 52, train_loss 0.16207671165466309, val_loss 0.14466463029384613 \n","Epoch 00059: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00065: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00071: reducing learning rate of group 0 to 1.9531e-05.\n","    Record loss - saving at epoch 74\n","    epoch 74, train_loss 0.16190333664417267, val_loss 0.14461883902549744 \n","Epoch 00081: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00087: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00093: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00099: reducing learning rate of group 0 to 1.2207e-06.\n","epoch 100, train_loss 0.1614905297756195, val_loss 0.14687320590019226 \n","Epoch 00105: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00111: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00117: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00123: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00129: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00135: reducing learning rate of group 0 to 1.9073e-08.\n","epoch 150, train_loss 0.16040800511837006, val_loss 0.14688582718372345 \n","epoch 200, train_loss 0.16305169463157654, val_loss 0.14887842535972595 \n","epoch 250, train_loss 0.16332197189331055, val_loss 0.14574505388736725 \n","epoch 300, train_loss 0.18767867982387543, val_loss 0.14652317762374878 \n","epoch 350, train_loss 0.16220971941947937, val_loss 0.14690811932086945 \n","epoch 400, train_loss 0.16128067672252655, val_loss 0.14712028205394745 \n","epoch 450, train_loss 0.16241753101348877, val_loss 0.14705972373485565 \n","epoch 500, train_loss 0.16429173946380615, val_loss 0.14739784598350525 \n","epoch 550, train_loss 0.1636267900466919, val_loss 0.14747273921966553 \n","max patience reached, stopping training\n"]}],"source":["# training loop\n","lowest_val_loss = 0\n","best_loss = False\n","\n","max_patience = 500\n","curr_patience = max_patience\n","\n","# datetime object containing current date and time\n","best_epoch = 0\n","now = datetime.now()\n","dt_string = now.strftime(f\"models/{model.model_type}_%d-%m-%Y_%H-%M-%S\")\n","\n","os.mkdir(os.path.join(\".\", dt_string))\n","\n","with open(f'{dt_string}/model_structure.txt', \"w\") as model_structure:\n","    model_structure.write(str(model))\n","    model_structure.write(f\"total params: {total_params}\")\n","\n","results_folder = audio_folder + \"/results\"\n","if not os.path.exists(results_folder):\n","    os.mkdir(results_folder)\n","results_folder += output_folder[0:len(output_folder)-1] + str(lstm_hidden_size) + \"/\"\n","if not os.path.exists(results_folder):\n","    os.mkdir(results_folder)\n","\n","for epoch in range(max_epochs):\n","    #ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimizer, device=device)\n","    ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimizer, device=device)\n","\n","    #ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimizer, device=device)\n","    val_loss = myk_train.compute_batch_loss(model, val_dl, loss_functions, device=device)\n","    scheduler.step(val_loss);\n","\n","    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n","    writer.add_scalar(\"Loss/train\", ep_loss, epoch)\n","    writer.add_scalar(\"LR\", optimizer.param_groups[0]['lr'], epoch)\n","\n","    # check if we have beaten our best loss to date\n","    if lowest_val_loss == 0:# first run\n","        lowest_val_loss = val_loss\n","    elif val_loss < lowest_val_loss:# new record\n","        lowest_val_loss = val_loss\n","        best_loss = True\n","    else: # no improvement\n","        best_loss = False\n","        curr_patience -= 1\n","\n","    if best_loss: # save best model so far\n","        best_epoch = epoch\n","        print(f\"    Record loss - saving at epoch {epoch}\")\n","        # save for RTNeural\n","        model.save_for_rtneural(f\"{dt_string}/model.json\")\n","        # save for pythorch\n","        torch.save(model.state_dict(), f\"{dt_string}/model.ph\")\n","        print(f\"    epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","        curr_patience = max_patience\n","    if epoch % 50 == 0: # save an example processed audio file\n","        myk_evaluate_par.run_file_through_model(model, test_file, results_folder + run_name + str(epoch)+\".wav\")\n","        print(f\"epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","    if curr_patience == 0:\n","        print(\"max patience reached, stopping training\")\n","        # load best parameters in the model\n","        model.load_state_dict(torch.load(f\"{dt_string}/model.ph\"))\n","        model.eval() # set inference state in the possible layers that need it\n","        myk_evaluate_par.run_file_through_model(model, test_file, results_folder + run_name + str(best_epoch)+\"_BEST.wav\", final_eval=True)\n","        break"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692897706510,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"edQeVKnKqIlY"},"outputs":[],"source":["to_append = [f'\\n{run_name}/**/*.wav', f'\\n!{run_name}/**/*_BEST*.wav', f'\\n!{run_name}/output*/*.wav']\n","\n","with open(f'{audio_folder}/../.gitignore', \"r+\") as gitignore:\n","    read = gitignore.read()\n","    if to_append[0][2:len(to_append[0])] not in read:\n","        gitignore.writelines(to_append)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1R90W11c0RiDl3RfZT-sX8pRNVVVbmSYh","timestamp":1685016693193}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}