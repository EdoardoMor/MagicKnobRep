{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2112,"status":"ok","timestamp":1690031835100,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"AUk8TQCYzAAe","outputId":"fcbaff53-b993-4875-b6a5-a9347256ad2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/macdonald/Desktop/MagicKnobRep/MagicKnob/python\n"]}],"source":["import os\n","from datetime import datetime\n","\n","working_path = os.getcwd()\n","print(working_path)\n","\n","if working_path == '/content':\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    %cd /content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob\n","\n","    path = \"/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}tensorflow\"\n","    %cd ./python\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\"\n","else:\n","    path = \"../\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1725,"status":"ok","timestamp":1690031836823,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"Wgz6WkLZzHDM"},"outputs":[],"source":["import myk_data_par\n","import myk_models\n","import myk_loss\n","import myk_train\n","import myk_evaluate_par\n","\n","import torch\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3904,"status":"ok","timestamp":1690031840725,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"mX_cQAvgzMLR"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-07-23 11:57:17.486329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":402,"status":"ok","timestamp":1690031874223,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"FXrHBuv6zQPg"},"outputs":[],"source":["# used for the writing of example outputs\n","run_name=\"audio_lstm_lpf_par\"\n","# dataset : need an input and output folder in this folder\n","audio_folder = f\"../data/{run_name}\"\n","#audio_folder = \"../../data/audio_ht1\"\n","assert os.path.exists(audio_folder), f\"Audio folder  not found. Looked for {audio_folder}\"\n","# used to render example output during training\n","test_file = \"../data/guitar.wav\"\n","assert os.path.exists(test_file), \"Test file not found. Looked for \" + test_file"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1690031874794,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"wJPGiuLV0ylP"},"outputs":[],"source":["# initialize net specs\n","lstm_hidden_size = 16\n","learning_rate = 5e-3\n","last_learning_rate = learning_rate\n","batch_size = 50\n","max_epochs = 10000\n","\n","# create the logger for tensorboard\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8921,"status":"ok","timestamp":1690031892125,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"izzFWaHj0zej","outputId":"d73ef704-9f7a-428f-9dd9-97610c4b49fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading dataset from folder  ../data/audio_lstm_lpf_par\n","loading input and output of filter\n","    loading output of filter with parameter 0\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (120, 22050, 2)\n","    total output shape: (120, 22050, 1)\n","\n","    loading output of filter with parameter 0.25\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (240, 22050, 2)\n","    total output shape: (240, 22050, 1)\n","\n","    loading output of filter with parameter 0.5\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (360, 22050, 2)\n","    total output shape: (360, 22050, 1)\n","\n","    loading output of filter with parameter 0.75\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (480, 22050, 2)\n","    total output shape: (480, 22050, 1)\n","\n","    loading output of filter with parameter 1\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 2)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (600, 22050, 2)\n","    total output shape: (600, 22050, 1)\n","\n","total input tensor shape torch.Size([600, 22050, 2])\n","total output tensor shape torch.Size([600, 22050, 1])\n","Splitting dataset\n"]}],"source":["print(\"Loading dataset from folder \", audio_folder)\n","dataset = myk_data_par.generate_dataset(audio_folder + \"/input/\", audio_folder + \"/output/\", frag_len_seconds=0.5)\n","\n","print(\"Splitting dataset\")\n","train_ds, val_ds, test_ds = myk_data_par.get_train_valid_test_datasets(dataset)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1690031892126,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"p5wnmGGzU1KX","outputId":"5f3fd97d-6db1-4c32-b796-bb8640ef8c50"},"outputs":[{"data":{"text/plain":["(tensor([[-3.0518e-05,  0.0000e+00],\n","         [-3.0518e-05,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00]]),\n"," tensor([[ 0.0000e+00],\n","         [ 0.0000e+00],\n","         [ 0.0000e+00],\n","         ...,\n","         [-1.4067e-05],\n","         [-1.3947e-05],\n","         [-1.3947e-05]]))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda device not available/not selected\n"]}],"source":["\n","# test GPU, must be done after splitting\n","device = myk_train.get_device()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1690031892127,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"D3WztACX2UOd"},"outputs":[],"source":["# create data loaders\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4118,"status":"ok","timestamp":1690031896228,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"8JZL-Qqa2ORT","outputId":"a98c6bc2-9db5-4582-b270-71f917176461"},"outputs":[{"name":"stdout","output_type":"stream","text":["SimpleLSTM(\n","  (lstm): LSTM(2, 16, batch_first=True)\n","  (dense): Linear(in_features=16, out_features=1, bias=True)\n",")\n"]},{"data":{"text/plain":["(None, 1297)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model = myk_models.SimpleLSTM(hidden_size=lstm_hidden_size, param=True).to(device)\n","total_params = sum(p.numel() for p in model.parameters())\n","print(model), total_params"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1690031896228,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"4CuDKuR92cxv"},"outputs":[],"source":["# crate optimizer and loss function\n","optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', factor=0.5, patience=5, verbose=True)\n","\n","loss_functions = myk_loss.LossWrapper()\n","\n","# https://github.com/Alec-Wright/Automated-GuitarAmpModelling/blob/main/dist_model_recnet.py\n","# https://github.com/Alec-Wright/CoreAudioML/blob/bad9469f94a2fa63a50d70ff75f5eff2208ba03f/training.py"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690031896228,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"-6cmEvsqHwL7"},"outputs":[],"source":["#%load_ext tensorboard\n","#%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550145,"status":"ok","timestamp":1690032446371,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"L2_vgpXU2tvW","outputId":"92a830fd-90bd-4936-809c-cd70304db85e"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch 0, train_loss 0.6590960621833801, val_loss 0.43399983644485474 \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     model_structure\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtotal params: \u001b[39m\u001b[39m{\u001b[39;00mtotal_params\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_epochs):\n\u001b[1;32m     20\u001b[0m     \u001b[39m#ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     ep_loss \u001b[39m=\u001b[39m myk_train\u001b[39m.\u001b[39;49mtrain_epoch_interval(model, train_dl, loss_functions, optimiser, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     23\u001b[0m     \u001b[39m#ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimiser, device=device)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     val_loss \u001b[39m=\u001b[39m myk_train\u001b[39m.\u001b[39mcompute_batch_loss(model, val_dl, loss_functions, device\u001b[39m=\u001b[39mdevice)\n","File \u001b[0;32m~/Desktop/MagicKnobRep/MagicKnob/python/myk_train.py:88\u001b[0m, in \u001b[0;36mtrain_epoch_interval\u001b[0;34m(model, dataloader, loss_functions, optimiser, device, warm_up_len, sub_batch_seq_len)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m#print(\"B\", batch_idx, \"has subs \", available_sub_batches, \"s\", start_sample, \"e\", end_sample)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39mfor\u001b[39;00m sub_batch_ind \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(available_sub_batches):\n\u001b[1;32m     87\u001b[0m     \u001b[39m#print(\"B\", batch_idx, \"sb\", sub_batch_ind, \"s\", start_sample, \"e\", end_sample)\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(inputs[:,start_sample:end_sample, :])\n\u001b[1;32m     89\u001b[0m     \u001b[39m# send in the inputs, skipping the warm up sequence\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     loss \u001b[39m=\u001b[39m loss_functions(outputs, targets[:,start_sample:end_sample, :])\n","File \u001b[0;32m~/Desktop/MagicKnobRep/MagicKnob/python/myk_models.py:52\u001b[0m, in \u001b[0;36mSimpleLSTM.forward\u001b[0;34m(self, torch_in)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_hidden \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(torch_in)\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(x)\n","File \u001b[0;32m~/opt/miniconda3/envs/STMAE/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/opt/miniconda3/envs/STMAE/lib/python3.11/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# training loop\n","lowest_val_loss = 0\n","best_loss = False\n","\n","max_patience = 500\n","curr_patience = max_patience\n","\n","# datetime object containing current date and time\n","best_epoch = 0\n","now = datetime.now()\n","dt_string = now.strftime(f\"models/{model.model_type}_%d-%m-%Y_%H-%M-%S\")\n","\n","os.mkdir(os.path.join(\".\", dt_string))\n","\n","with open(f'{dt_string}/model_structure.txt', \"w\") as model_structure:\n","    model_structure.write(str(model))\n","    model_structure.write(f\"total params: {total_params}\")\n","\n","for epoch in range(max_epochs):\n","    #ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\n","    ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\n","\n","    #ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimiser, device=device)\n","    val_loss = myk_train.compute_batch_loss(model, val_dl, loss_functions, device=device)\n","    scheduler.step(val_loss);\n","\n","    if learning_rate != last_learning_rate:\n","      print(f\"LR step {learning_rate}\")\n","\n","    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n","    writer.add_scalar(\"Loss/train\", ep_loss, epoch)\n","\n","    # check if we have beaten our best loss to date\n","    if lowest_val_loss == 0:# first run\n","        lowest_val_loss = val_loss\n","    elif val_loss < lowest_val_loss:# new record\n","        lowest_val_loss = val_loss\n","        best_loss = True\n","    else: # no improvement\n","        best_loss = False\n","        curr_patience -= 1\n","\n","    if best_loss: # save best model so far\n","        best_epoch = epoch\n","        print(f\"    Record loss - saving at epoch {epoch}\")\n","        # save for RTNeural\n","        model.save_for_rtneural(f\"{dt_string}/model.json\")\n","        # save for pythorch\n","        torch.save(model.state_dict(), f\"{dt_string}/model.ph\")\n","        print(f\"    epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","        curr_patience = max_patience\n","    if epoch % 50 == 0: # save an example processed audio file\n","        myk_evaluate_par.run_file_through_model(model, test_file, audio_folder + \"/\" + run_name + str(epoch)+\".wav\")\n","        print(f\"epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","    if curr_patience == 0:\n","        print(\"max patience reached, stopping training\")\n","        # load best parameters in the model\n","        model.load_state_dict(torch.load(f\"{dt_string}/model.ph\"))\n","        model.eval() # set inference state in the possible layers that need it\n","        myk_evaluate_par.run_file_through_model(model, test_file, audio_folder + \"/\" + run_name + str(best_epoch)+\"_BEST.wav\", final_eval=True)\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"executionInfo":{"elapsed":28,"status":"error","timestamp":1690032446372,"user":{"displayName":"FireHead Vlogs","userId":"00714204215770433149"},"user_tz":-120},"id":"edQeVKnKqIlY","outputId":"6a6456ec-a586-40ac-8c26-02eb60c19650"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-4d12a0fc0560>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mto_append\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf'\\n{run_name}/*.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'\\n!{run_name}/*_BEST*.wav'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{audio_folder}/../.gitignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgitignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgitignore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_append\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_append\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/audio_logic_dist_par/../.gitignore'"]}],"source":["to_append = [f'\\n{run_name}/*.wav', f'\\n!{run_name}/*_BEST*.wav']\n","\n","with open(f'{audio_folder}/../.gitignore', \"r+\") as gitignore:\n","    read = gitignore.read()\n","    if to_append[0][2:len(to_append[0])] not in read:\n","        gitignore.writelines(to_append)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1R90W11c0RiDl3RfZT-sX8pRNVVVbmSYh","timestamp":1685016693193}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
