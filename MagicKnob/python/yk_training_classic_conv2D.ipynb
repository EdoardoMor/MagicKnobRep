{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22440,"status":"ok","timestamp":1687945382891,"user":{"displayName":"Edoardo Morena","userId":"04340216690173222044"},"user_tz":-120},"id":"SzZkl2XVHkdC","outputId":"38d91784-c81f-4a78-e7dc-30944c344548"},"outputs":[],"source":["import os\n","from datetime import datetime\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1687945382891,"user":{"displayName":"Edoardo Morena","userId":"04340216690173222044"},"user_tz":-120},"id":"4wtUroX4yNjm","outputId":"ae607837-d9d6-4d26-cacf-0523099dbb97"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: '/content'\n","/Users/macdonald/Desktop/MagicKnobRep/MagicKnob/python\n","\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m/                      myk_train.py\n","myk_data.py                       \u001b[31mmyk_train_conv.py\u001b[m\u001b[m*\n","\u001b[31mmyk_data_conv.py\u001b[m\u001b[m*                 \u001b[1m\u001b[36mruns\u001b[m\u001b[m/\n","myk_evaluate.py                   train.py\n","\u001b[31mmyk_evaluate_conv.py\u001b[m\u001b[m*             yk_training.ipynb\n","myk_loss.py                       \u001b[31myk_training_classic_conv1D.ipynb\u001b[m\u001b[m*\n","myk_models.py                     \u001b[31myk_training_classic_conv2D.ipynb\u001b[m\u001b[m*\n","\u001b[31mmyk_models_conv.py\u001b[m\u001b[m*\n"]}],"source":["%cd /content\n","%ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1042,"status":"ok","timestamp":1687945383922,"user":{"displayName":"Edoardo Morena","userId":"04340216690173222044"},"user_tz":-120},"id":"AUk8TQCYzAAe","outputId":"65f4d935-6e97-4993-e7e1-881763b1d567"},"outputs":[],"source":["drive = False\n","if drive:\n","    path = \"/content/drive/MyDrive/Progetto_MagicKnob/\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"yk_training_files\"), f\"Upload python files in {path}yk_training_files\"\n","    %cd ./drive/MyDrive/Progetto_MagicKnob/yk_training_files\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\""]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Wgz6WkLZzHDM"},"outputs":[],"source":["#import myk_data\n","#import myk_models\n","import myk_loss\n","#import myk_train\n","\n","import myk_data_conv\n","import myk_models_conv\n","import myk_train_conv\n","import torch\n","from torch.utils.data import DataLoader\n","#import myk_evaluate\n","import myk_evaluate_conv"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"mX_cQAvgzMLR"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FXrHBuv6zQPg"},"outputs":[],"source":["# used for the writing of example outputs\n","run_name=\"audio_conv2D\"\n","# dataset : need an input and output folder in this folder\n","audio_folder = \"../data/audio_conv2D\"\n","assert os.path.exists(audio_folder), \"Audio folder  not found. Looked for \" + audio_folder\n","# used to render example output during training\n","test_file = \"../data/guitar.wav\"\n","assert os.path.exists(test_file), \"Test file not found. Looked for \" + test_file"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wJPGiuLV0ylP"},"outputs":[],"source":["# initialize net specs\n","lstm_hidden_size = 32\n","learning_rate = 5e-3\n","batch_size = 50\n","max_epochs = 10000\n","\n","# create the logger for tensorboard\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686675493880,"user":{"displayName":"Edoardo Morena","userId":"04340216690173222044"},"user_tz":-120},"id":"izzFWaHj0zej","outputId":"adaf3dc1-4bb6-47d2-f676-d46236e121ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["generate_dataset:: Loaded frames from audio file 120\n","input tensor shape torch.Size([120, 22050, 1])\n"]}],"source":["# Reading dataset\n","dataset = myk_data_conv.generate_dataset(audio_folder + \"/input/\", audio_folder + \"/output/\", frag_len_seconds=0.5)\n","\n","# slitting ds into train val test\n","train_ds, val_ds, test_ds = myk_data_conv.get_train_valid_test_datasets(dataset)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1686675494306,"user":{"displayName":"Edoardo Morena","userId":"04340216690173222044"},"user_tz":-120},"id":"p5wnmGGzU1KX","outputId":"ea45b91a-b537-4cda-ddf7-6d2c85c128d0"},"outputs":[{"data":{"text/plain":["(tensor([[-3.0518e-05],\n","         [-3.0518e-05],\n","         [ 0.0000e+00],\n","         ...,\n","         [ 0.0000e+00],\n","         [ 0.0000e+00],\n","         [ 0.0000e+00]]),\n"," tensor([[ 0.0000e+00],\n","         [-4.1723e-06],\n","         [ 8.3447e-06],\n","         ...,\n","         [ 6.1035e-04],\n","         [ 1.5259e-03],\n","         [ 1.2207e-03]]))"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1686675494307,"user":{"displayName":"Edoardo Morena","userId":"04340216690173222044"},"user_tz":-120},"id":"KpY8DxYl1Cb0","outputId":"7b65e61d-b040-423b-da02-39bb931114fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda device not available/not selected\n"]}],"source":["# test GPU, must be done after splitting\n","device = myk_train_conv.get_device()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"D3WztACX2UOd"},"outputs":[],"source":["# create data loaders\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8JZL-Qqa2ORT"},"outputs":[],"source":["model = myk_models_conv.SimpleConv2D().to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"4CuDKuR92cxv"},"outputs":[],"source":["# crate optimizer and loss function\n","optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', factor=0.5, patience=5, verbose=True) non lo usava\n","\n","loss_functions = myk_loss.LossWrapper()\n","\n","# https://github.com/Alec-Wright/Automated-GuitarAmpModelling/blob/main/dist_model_recnet.py\n","# https://github.com/Alec-Wright/CoreAudioML/blob/bad9469f94a2fa63a50d70ff75f5eff2208ba03f/training.py"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-6cmEvsqHwL7"},"outputs":[],"source":["#%load_ext tensorboard\n","#%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1107431,"status":"ok","timestamp":1686676604698,"user":{"displayName":"Edoardo Morena","userId":"04340216690173222044"},"user_tz":-120},"id":"L2_vgpXU2tvW","outputId":"de3858f2-71ac-449a-bc1d-6c5a4a81cba3"},"outputs":[{"name":"stdout","output_type":"stream","text":["input shape: torch.Size([50, 22050, 1])\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m os\u001b[39m.\u001b[39mmkdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, dt_string))\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_epochs):\n\u001b[1;32m     15\u001b[0m     \u001b[39m#ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     ep_loss \u001b[39m=\u001b[39m myk_train_conv\u001b[39m.\u001b[39;49mtrain_epoch_conv(model, train_dl, loss_functions, optimiser, device\u001b[39m=\u001b[39;49mdevice) \u001b[39m#decomment per conv\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m#ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimiser, device=device)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     val_loss \u001b[39m=\u001b[39m myk_train_conv\u001b[39m.\u001b[39mcompute_batch_loss(model, val_dl, loss_functions, device\u001b[39m=\u001b[39mdevice)\n","File \u001b[0;32m~/Desktop/MagicKnobRep/MagicKnob/python/myk_train_conv.py:125\u001b[0m, in \u001b[0;36mtrain_epoch_conv\u001b[0;34m(model, dataloader, loss_functions, optimiser, device, sub_batch_seq_len)\u001b[0m\n\u001b[1;32m    121\u001b[0m inputs, targets \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    123\u001b[0m \u001b[39m# warm up. shape: [batch,sequence,feature]   \u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m#model.zero_on_next_forward()  #COMMENTATO PER PROVARE SIMPLECONV\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m model\u001b[39m.\u001b[39;49mforward(inputs)\n\u001b[1;32m    126\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    127\u001b[0m \u001b[39m# now we iterate over in chunks of 2048\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# training at each step\u001b[39;00m\n","File \u001b[0;32m~/Desktop/MagicKnobRep/MagicKnob/python/myk_models_conv.py:170\u001b[0m, in \u001b[0;36mSimpleConv2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[1;32m    169\u001b[0m \u001b[39m# input 32 channels, output 64 channels\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact3(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(x))\n\u001b[1;32m    172\u001b[0m \u001b[39m# input 64 channels, output 32 channels\u001b[39;00m\n\u001b[1;32m    173\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact4(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(x))\n","File \u001b[0;32m~/opt/miniconda3/envs/STMAE/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/opt/miniconda3/envs/STMAE/lib/python3.11/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n","File \u001b[0;32m~/opt/miniconda3/envs/STMAE/lib/python3.11/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# training loop\n","lowest_val_loss = 0\n","best_loss = False\n","\n","max_patience = 500\n","curr_patience = max_patience\n","\n","# datetime object containing current date and time\n","now = datetime.now()\n","dt_string = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n","\n","os.mkdir(os.path.join(\".\", dt_string))\n","\n","for epoch in range(max_epochs):\n","    #ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\n","    ep_loss = myk_train_conv.train_epoch_conv(model, train_dl, loss_functions, optimiser, device=device) #decomment per conv\n","\n","    #ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimiser, device=device)\n","    val_loss = myk_train_conv.compute_batch_loss(model, val_dl, loss_functions, device=device)\n","    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n","    writer.add_scalar(\"Loss/train\", ep_loss, epoch)\n","\n","    # check if we have beaten our best loss to date\n","    if lowest_val_loss == 0:# first run\n","        lowest_val_loss = val_loss\n","    elif val_loss < lowest_val_loss:# new record\n","        lowest_val_loss = val_loss\n","        best_loss = True\n","    else: # no improvement\n","        best_loss = False\n","        curr_patience -= 1\n","\n","    if best_loss: # save best model so far\n","        print(\"    Record loss - saving at epoch \", epoch)\n","        model.save_for_rtneural(f\"{dt_string}/model.json\")\n","        print(f\"   epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","        curr_patience = max_patience\n","    if epoch % 50 == 0: # save an example processed audio file\n","        myk_evaluate_conv.run_file_through_model(model, test_file, audio_folder + \"/\" + run_name + str(epoch)+\".wav\")\n","        print(f\"epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss}\")\n","    if curr_patience == 0:\n","        print(\"max patience reached, stopping\")\n","        break"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1R90W11c0RiDl3RfZT-sX8pRNVVVbmSYh","timestamp":1685016693193}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
