{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2340,"status":"ok","timestamp":1690213384290,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"AUk8TQCYzAAe","outputId":"fee54204-04f6-40b6-d455-e829e447422c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob\n","/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/python\n"]}],"source":["import os\n","from datetime import datetime\n","\n","working_path = os.getcwd()\n","print(working_path)\n","\n","if working_path == '/content':\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    %cd /content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob\n","\n","    path = \"/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","    %cd ./python\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\"\n","else:\n","    path = \"../\"\n","\n","    # check python file folder\n","    assert os.path.exists(path + \"python\"), f\"Upload python files in {path}python\"\n","\n","    # check data folder\n","    assert os.path.exists(path + \"data\"), f\"Upload data files in {path}data\""]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Wgz6WkLZzHDM","executionInfo":{"status":"ok","timestamp":1690213386633,"user_tz":-120,"elapsed":2345,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["import myk_data\n","import myk_models\n","import myk_loss\n","import myk_train\n","import myk_evaluate\n","\n","import torch\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"mX_cQAvgzMLR","executionInfo":{"status":"ok","timestamp":1690213395052,"user_tz":-120,"elapsed":8421,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FXrHBuv6zQPg","executionInfo":{"status":"ok","timestamp":1690213395052,"user_tz":-120,"elapsed":18,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["# used for the writing of example outputs\n","run_name=\"audio_lstm_phaser\"\n","# dataset : need an input and output folder in this folder\n","audio_folder = f\"../data/{run_name}\"\n","#audio_folder = \"../../data/audio_ht1\"\n","assert os.path.exists(audio_folder), f\"Audio folder  not found. Looked for {audio_folder}\"\n","# used to render example output during training\n","test_file = \"../data/guitar.wav\"\n","assert os.path.exists(test_file), \"Test file not found. Looked for \" + test_file"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"wJPGiuLV0ylP","executionInfo":{"status":"ok","timestamp":1690213395053,"user_tz":-120,"elapsed":18,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["# initialize net specs\n","lstm_hidden_size = 16\n","learning_rate = 5e-3\n","batch_size = 50\n","max_epochs = 10000\n","\n","# create the logger for tensorboard\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1690213395491,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"izzFWaHj0zej","outputId":"b89a76b4-e788-4525-da25-eda105f18bb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading dataset from folder  ../data/audio_lstm_phaser\n","loading input and output of phaser\n","    loading output of phaser\n","    generate_dataset:: Loaded frames from audio file 22050\n","    found input fragments of shape (120, 22050, 1)\n","    found output fragments of shape (120, 22050, 1)\n","    total input shape: (120, 22050, 1)\n","    total output shape: (120, 22050, 1)\n","\n","total input tensor shape torch.Size([120, 22050, 1])\n","total output tensor shape torch.Size([120, 22050, 1])\n","Splitting dataset\n"]}],"source":["print(\"Loading dataset from folder \", audio_folder)\n","dataset = myk_data.generate_dataset(audio_folder + \"/input/\", audio_folder + \"/output/\", frag_len_seconds=0.5)\n","\n","print(\"Splitting dataset\")\n","train_ds, val_ds, test_ds = myk_data.get_train_valid_test_datasets(dataset)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1690213395491,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"p5wnmGGzU1KX","outputId":"3c8c1514-786f-4946-a5bf-e818dcd3ba4f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-3.0518e-05],\n","         [-3.0518e-05],\n","         [ 0.0000e+00],\n","         ...,\n","         [ 0.0000e+00],\n","         [ 0.0000e+00],\n","         [ 0.0000e+00]]),\n"," tensor([[ 0.0000e+00],\n","         [ 0.0000e+00],\n","         [ 0.0000e+00],\n","         ...,\n","         [-3.8624e-05],\n","         [-2.5749e-05],\n","         [-1.6809e-05]]))"]},"metadata":{},"execution_count":7}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1690213395492,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"KpY8DxYl1Cb0","outputId":"aa2abcb6-7b88-47c5-bef0-bdcb99015e59"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda device available\n"]}],"source":["# test GPU, must be done after splitting\n","device = myk_train.get_device()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"D3WztACX2UOd","executionInfo":{"status":"ok","timestamp":1690213395492,"user_tz":-120,"elapsed":3,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["# create data loaders\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))\n","test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, generator=torch.Generator(device=device))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3185,"status":"ok","timestamp":1690213398674,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"8JZL-Qqa2ORT","outputId":"1141d934-7ec6-493e-a107-e6d3d3296efb"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleLSTM(\n","  (lstm): LSTM(1, 16, batch_first=True)\n","  (dense): Linear(in_features=16, out_features=1, bias=True)\n",")\n"]},{"output_type":"execute_result","data":{"text/plain":["(None, 1233)"]},"metadata":{},"execution_count":10}],"source":["model = myk_models.SimpleLSTM(hidden_size=lstm_hidden_size).to(device)\n","total_params = sum(p.numel() for p in model.parameters())\n","print(model), total_params"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"4CuDKuR92cxv","executionInfo":{"status":"ok","timestamp":1690213398675,"user_tz":-120,"elapsed":16,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["# crate optimizer and loss function\n","optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', factor=0.5, patience=100, verbose=True) # non lo usava\n","\n","loss_functions = myk_loss.LossWrapper()\n","\n","# https://github.com/Alec-Wright/Automated-GuitarAmpModelling/blob/main/dist_model_recnet.py\n","# https://github.com/Alec-Wright/CoreAudioML/blob/bad9469f94a2fa63a50d70ff75f5eff2208ba03f/training.py"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"-6cmEvsqHwL7","executionInfo":{"status":"ok","timestamp":1690213398675,"user_tz":-120,"elapsed":15,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["#%load_ext tensorboard\n","#%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"executionInfo":{"elapsed":737,"status":"error","timestamp":1690213399397,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"L2_vgpXU2tvW","outputId":"ca76bc7e-12b3-44bf-e1d3-28516d2b10f9"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-aa1364697b61>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyk_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimiser, device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/Il mio MacBook Pro/MagicKnob/python/myk_train.py\u001b[0m in \u001b[0;36mtrain_epoch_interval\u001b[0;34m(model, dataloader, loss_functions, optimiser, device, warm_up_len, sub_batch_seq_len)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# send in the inputs, skipping the warm up sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [50, 2048, 16]], which is output 0 of CudnnRnnBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."]}],"source":["# training loop\n","lowest_val_loss = 0\n","best_loss = False\n","\n","max_patience = 500\n","curr_patience = max_patience\n","\n","# datetime object containing current date and time\n","best_epoch = 0\n","now = datetime.now()\n","dt_string = now.strftime(f\"models/{model.model_type}_%d-%m-%Y_%H-%M-%S\")\n","\n","os.mkdir(os.path.join(\".\", dt_string))\n","\n","with open(f'{dt_string}/model_structure.txt', \"w\") as model_structure:\n","    model_structure.write(str(model))\n","\n","for epoch in range(max_epochs):\n","    #ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\n","    ep_loss = myk_train.train_epoch_interval(model, train_dl, loss_functions, optimiser, device=device)\n","\n","    #ep_loss = myk_train.train_epoch(model, train_dl, loss_functions, optimiser, device=device)\n","    val_loss = myk_train.compute_batch_loss(model, val_dl, loss_functions, device=device)\n","\n","    scheduler.step(val_loss)\n","\n","    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n","    writer.add_scalar(\"Loss/train\", ep_loss, epoch)\n","\n","    # check if we have beaten our best loss to date\n","    if lowest_val_loss == 0: # first run\n","        lowest_val_loss = val_loss\n","    elif val_loss < lowest_val_loss:# new record\n","        lowest_val_loss = val_loss\n","        best_loss = True\n","    else: # no improvement\n","        best_loss = False\n","        curr_patience -= 1\n","\n","    if best_loss: # save best model so far\n","        best_epoch = epoch\n","        print(f\"    Record loss - saving at epoch {epoch}\")\n","        # save for RTNeural\n","        model.save_for_rtneural(f\"{dt_string}/model.json\")\n","        # save for pythorch\n","        torch.save(model.state_dict(), f\"{dt_string}/model.ph\")\n","        print(f\"    epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","        curr_patience = max_patience\n","    if epoch % 50 == 0: # save an example processed audio file\n","        myk_evaluate.run_file_through_model(model, test_file, audio_folder + \"/\" + run_name + str(epoch)+\".wav\")\n","        print(f\"epoch {epoch}, train_loss {ep_loss}, val_loss {val_loss} \")\n","    if curr_patience == 0:\n","        print(\"max patience reached, stopping training\")\n","        # load best parameters in the model\n","        model.load_state_dict(torch.load(f\"{dt_string}/model.ph\"))\n","        model.eval() # set inference state in the possible layers that need it\n","        myk_evaluate.run_file_through_model(model, test_file, audio_folder + \"/\" + run_name + str(best_epoch)+\"_BEST.wav\")\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edQeVKnKqIlY","executionInfo":{"status":"aborted","timestamp":1690213399398,"user_tz":-120,"elapsed":4,"user":{"displayName":"Niccolò","userId":"04990246452610004701"}}},"outputs":[],"source":["to_append = [f'\\n{run_name}/*.wav', f'\\n!{run_name}/*_BEST*.wav']\n","\n","with open(f'{audio_folder}/../.gitignore', \"r+\") as gitignore:\n","    read = gitignore.read()\n","    if to_append[0][2:len(to_append[0])] not in read:\n","        gitignore.writelines(to_append)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1R90W11c0RiDl3RfZT-sX8pRNVVVbmSYh","timestamp":1685016693193}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}